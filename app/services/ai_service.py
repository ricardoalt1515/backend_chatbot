import logging
import re
from typing import List, Dict, Any, Optional, Tuple
import httpx
import time
import json
from datetime import datetime

from app.config import settings
from app.models.conversation import Conversation
from app.services.questionnaire_service import questionnaire_service

# Intento importar el contador de tokens si est치 disponible
try:
    from app.utils.token_counter import count_tokens, estimate_cost

    token_counter_available = True
except ImportError:
    token_counter_available = False

logger = logging.getLogger("hydrous-backend")

# Lista de preguntas cr칤ticas que requieren respuestas completas
CRITICAL_QUESTIONS = {
    "cantidad_agua_consumida": {
        "explanation": "el consumo de agua es fundamental para dimensionar correctamente el sistema",
        "fallback": "un rango aproximado (por ejemplo: entre 10-50 m췁/d칤a) nos permitir칤a avanzar",
        "validation": lambda x: any(
            term in x.lower() for term in ["m3", "m췁", "litro", "l/", "metro"]
        ),
    },
    "costo_agua": {
        "explanation": "el costo del agua es clave para calcular el retorno de inversi칩n",
        "fallback": "incluso un valor aproximado nos ayudar칤a a estimar los ahorros potenciales",
        "validation": lambda x: any(
            term in x.lower() for term in ["$", "peso", "mxn", "usd", "dolar"]
        ),
    },
    "ubicacion": {
        "explanation": "la ubicaci칩n influye en las normativas aplicables y disponibilidad de recursos",
        "fallback": "al menos la ciudad o municipio nos permitir칤a contextualizar mejor la soluci칩n",
        "validation": lambda x: len(x) > 5,  # Verificaci칩n b치sica de longitud
    },
}


class AIService:
    """Servicio para interactuar con modelos de IA"""

    def __init__(self):
        super().__init__()
        # Inicializar el atributo questionnaire_service
        from app.services.questionnaire_service import questionnaire_service

        self.questionnaire_service = questionnaire_service
        self.provider = settings.AI_PROVIDER

        # En caso de que las bibliotecas groq y openai no est칠n instaladas,
        # utilizaremos httpx para hacer las solicitudes directamente
        self.groq_api_url = "https://api.groq.com/openai/v1/chat/completions"
        self.openai_api_url = "https://api.openai.com/v1/chat/completions"

        if self.provider == "groq":
            if not settings.GROQ_API_KEY:
                logger.warning(
                    "GROQ_API_KEY no configurada. Las llamadas a la API fallar치n."
                )
            self.api_key = settings.GROQ_API_KEY
            self.model = settings.GROQ_MODEL
            self.api_url = self.groq_api_url

        elif self.provider == "openai":
            if not settings.OPENAI_API_KEY:
                logger.warning(
                    "OPENAI_API_KEY no configurada. Las llamadas a la API fallar치n."
                )
            self.api_key = settings.OPENAI_API_KEY
            self.model = settings.OPENAI_MODEL
            self.api_url = self.openai_api_url

        else:
            # Si el proveedor no est치 configurado correctamente, usamos un modo de "fallback"
            logger.warning(
                f"Proveedor de IA no soportado: {self.provider}. Usando respuestas pre-configuradas."
            )
            self.api_key = None
            self.model = None
            self.api_url = None

        # Atributos para mantener el contexto entre llamadas
        self.current_sector = None
        self.current_subsector = None

    def _detect_questionnaire_intent(self, message: str) -> bool:
        """
        Como el cuestionario siempre debe iniciarse, este m칠todo siempre devuelve True
        """
        return True  # Siempre iniciar el cuestionario, sin importar el mensaje

    def get_initial_greeting(self) -> str:
        """
        Devuelve el mensaje de saludo inicial y primera pregunta del cuestionario
        """
        return """
Soy el dise침ador de soluciones de agua de Hydrous AI, su asistente experto para dise침ar soluciones personalizadas de tratamiento de agua y aguas residuales. Como herramienta de Hydrous, estoy aqu칤 para guiarlo paso a paso en la evaluaci칩n de las necesidades de agua de su sitio, la exploraci칩n de posibles soluciones y la identificaci칩n de oportunidades de ahorro de costos, cumplimiento y sostenibilidad.

Para desarrollar la mejor soluci칩n para sus instalaciones, har칠 sistem치ticamente preguntas espec칤ficas para recopilar los datos necesarios y crear una propuesta personalizada. Mi objetivo es ayudarlo a optimizar la gesti칩n del agua, reducir costos y explorar nuevas fuentes de ingresos con soluciones respaldadas por Hydrous.

*Las soluciones de reciclaje de agua pueden reducir el consumo de agua fresca hasta en un 70% en instalaciones industriales similares.*

El tratamiento adecuado del agua no solo es beneficioso para el medio ambiente, sino que puede representar un ahorro significativo en costos operativos a mediano y largo plazo.

**PREGUNTA: 쮼n qu칠 sector opera su empresa?**
1. Industrial
2. Comercial
3. Municipal
4. Residencial
"""

    def format_response_with_questions(
        self,
        previous_answer_comment,
        interesting_fact,
        question_context,
        question_text,
        question_id,
        options=None,
        document_suggestion=None,
    ):
        """
        Formatea una respuesta siguiendo la estructura establecida en el prompt original

        Args:
            previous_answer_comment: Comentario sobre la respuesta anterior
            interesting_fact: Dato interesante relacionado con el sector/industria
            question_context: Explicaci칩n de por qu칠 la pregunta es importante
            question_text: Texto de la pregunta
            options: Lista de opciones para preguntas de selecci칩n m칰ltiple
            document_suggestion: Sugerencia para subir un documento (opcional)

        Returns:
            str: Respuesta formateada seg칰n la estructura requerida
        """
        # Obtener emoji apropidado para la pregunta
        emoji = self._select_emoji_for_question_type(question_id)

        # 1. Comentario sobre respuesta anterior
        response = f"{previous_answer_comment}\n\n"

        # 2. Dato interesante en cursiva
        if interesting_fact:
            response += f"游눠 *{interesting_fact}*\n\n"

        # 3. Explicaci칩n de por qu칠 la pregunta es importante
        if question_context:
            response += f"{question_context}\n\n"

        # 4. La pregunta al final, en negrita y precedida por emoji contextual
        response += f"**{emoji} PREGUNTA: {question_text}**\n\n"

        # 5. Opciones numeradas para preguntas de opci칩n m칰ltiple
        if options:
            for i, option in enumerate(options, 1):
                response += f"{i}. {option}\n"

        # A침adir sugerencia de documento si es aplicable
        if document_suggestion:
            response += f"\n\n{document_suggestion}"

        return response

    def should_suggest_document(self, question_id: str) -> Optional[str]:
        """
        Determina si se debe sugerir subir un documento para esta pregunta
        y devuelve el texto de la sugerencia

        Args:
            question_id: ID de la pregunta actual

        Returns:
            str: Texto de sugerencia o None si no aplica
        """
        suggestions = {
            "parametros_agua": """
### 游늯 An치lisis de Laboratorio

Si dispone de an치lisis recientes de su agua residual, puede subirlos ahora usando el bot칩n de adjuntar archivo.
Estos datos nos permitir치n dise침ar una soluci칩n mucho m치s precisa y eficiente para su caso espec칤fico.
""",
            "costo_agua": """
### 游늯 Facturas de Agua

Si tiene a mano recibos recientes de agua, puede subirlos para un an치lisis m치s preciso de costos y potenciales ahorros.
Esta informaci칩n mejorar치 significativamente la exactitud de nuestros c치lculos de retorno de inversi칩n.
""",
            "sistema_existente": """
### 游늯 Documentaci칩n T칠cnica

Si dispone de documentaci칩n, diagramas o fotograf칤as de su sistema actual, nos ayudar칤a enormemente a entender 
su infraestructura existente y c칩mo integrar nuestra soluci칩n de la manera m치s eficiente.
""",
            "recibos_agua": """
### 游늯 Historial de Consumo

Compartir sus recibos de agua de los 칰ltimos meses nos permitir치 analizar patrones de consumo
y calcular con mayor precisi칩n los ahorros potenciales que podr칤a obtener.
""",
            "agua_potable_analisis": """
### 游늯 An치lisis de Agua Actual

Si cuenta con an치lisis de la calidad de su agua actual, subir estos documentos nos permitir치
entender mejor las caracter칤sticas espec칤ficas y dise침ar una soluci칩n m치s efectiva.
""",
        }

        return suggestions.get(question_id)

    def _generate_previous_answer_comment(
        self, conversation: Conversation, user_message: str
    ) -> str:
        """
        Genera un comentario personalizado sobre la respuesta anterior del usuario

        Args:
            conversation: Conversaci칩n actual
            user_message: Mensaje del usuario

        Returns:
            str: Comentario personalizado seg칰n el contexto
        """
        # Obtener el ID de la pregunta que se acaba de responder
        prev_question_id = conversation.questionnaire_state.current_question_id
        sector = conversation.questionnaire_state.sector
        subsector = conversation.questionnaire_state.subsector

        # Si no hay pregunta previa, es el inicio del cuestionario
        if not prev_question_id:
            return "Gracias por contactarnos. Me ayudar치 conocer algunos detalles sobre su empresa para ofrecerle la mejor soluci칩n personalizada."

        # Comentarios espec칤ficos para preguntas comunes
        if prev_question_id == "sector_selection":
            return f"Gracias por indicar que opera en el sector {sector}. Esto nos permite entender el contexto general de sus necesidades de tratamiento de agua."

        elif prev_question_id == "subsector_selection":
            return f"Excelente. El subsector {subsector} dentro del sector {sector} presenta desaf칤os y oportunidades espec칤ficas en el tratamiento de aguas residuales."

        elif prev_question_id == "nombre_empresa":
            empresa = conversation.questionnaire_state.answers.get(
                "nombre_empresa", "su empresa"
            )
            return f"Gracias por compartir que su empresa es {empresa}. Personalizaremos nuestra propuesta para adaptarla a sus necesidades espec칤ficas."

        elif prev_question_id == "ubicacion":
            ubicacion = conversation.questionnaire_state.answers.get(
                "ubicacion", "su ubicaci칩n"
            )
            return f"Entendido. La ubicaci칩n en {ubicacion} es importante ya que las regulaciones y condiciones ambientales var칤an seg칰n la regi칩n."

        elif prev_question_id == "costo_agua":
            costo = conversation.questionnaire_state.answers.get(
                "costo_agua", "el costo indicado"
            )
            return f"El costo de {costo} es un dato clave para calcular el retorno de inversi칩n y los ahorros potenciales de un sistema de reciclaje."

        elif prev_question_id == "cantidad_agua_consumida":
            consumo = conversation.questionnaire_state.answers.get(
                "cantidad_agua_consumida", "el consumo indicado"
            )
            return f"Un consumo de {consumo} nos permite dimensionar adecuadamente la soluci칩n y calcular los beneficios econ칩micos potenciales."

        elif prev_question_id == "cantidad_agua_residual":
            residual = conversation.questionnaire_state.answers.get(
                "cantidad_agua_residual", "la cantidad indicada"
            )
            return f"Perfecto. La generaci칩n de {residual} de agua residual es fundamental para el dise침o del sistema de tratamiento."

        elif prev_question_id == "parametros_agua":
            return "Los par치metros del agua que ha proporcionado son cruciales para determinar las tecnolog칤as y procesos de tratamiento espec칤ficos que necesita."

        elif prev_question_id == "objetivo_principal":
            objetivo = conversation.questionnaire_state.answers.get(
                "objetivo_principal", "su objetivo"
            )
            return f"Comprendo que su objetivo principal es {objetivo}. Esto guiar치 nuestra propuesta hacia los aspectos m치s relevantes para usted."

        elif prev_question_id == "objetivo_reuso":
            return "Sus objetivos de re칰so de agua nos ayudan a dise침ar un sistema que produzca agua con la calidad adecuada para las aplicaciones que necesita."

        elif prev_question_id == "sistema_existente":
            if "sistema_existente" in conversation.questionnaire_state.answers:
                respuesta = conversation.questionnaire_state.answers.get(
                    "sistema_existente"
                )
                if respuesta == "S칤" or respuesta == "Si" or respuesta == "1":
                    return "Es 칰til saber que ya cuenta con un sistema. Podemos evaluar c칩mo mejorarlo o complementarlo para optimizar sus resultados."
                else:
                    return "Entiendo que actualmente no cuenta con un sistema de tratamiento. Dise침aremos una soluci칩n completa desde cero."

        # Para otras preguntas, generar un comentario gen칠rico pero positivo
        return "Gracias por su respuesta. Cada dato que proporciona nos acerca m치s a dise침ar la soluci칩n 칩ptima para sus necesidades espec칤ficas."

    def _generate_interim_summary(self, conversation: Conversation) -> str:
        """
        Genera un resumen intermedio de la informaci칩n recopilada hasta el momento

        Args:
            conversation: Conversaci칩n actual

        Returns:
            str: Texto del resumen formateado
        """
        state = conversation.questionnaire_state
        answers = state.answers
        sector = state.sector
        subsector = state.subsector

        summary = f"""
## Resumen de la Informaci칩n Recopilada

Hemos avanzado en la recopilaci칩n de datos para su soluci칩n de tratamiento de agua. A continuaci칩n, un resumen de la informaci칩n proporcionada hasta el momento:

### Datos B치sicos
- **Sector**: {sector}
- **Subsector**: {subsector}
"""

        # A침adir respuestas clave en orden l칩gico
        key_fields = [
            ("nombre_empresa", "Empresa/Proyecto"),
            ("ubicacion", "Ubicaci칩n"),
            ("costo_agua", "Costo del agua"),
            ("cantidad_agua_consumida", "Consumo de agua"),
            ("cantidad_agua_residual", "Generaci칩n de agua residual"),
            ("objetivo_principal", "Objetivo principal"),
            ("objetivo_reuso", "Objetivos de re칰so"),
            ("sistema_existente", "Sistema existente"),
        ]

        info_added = False
        for field_id, field_name in key_fields:
            if field_id in answers:
                summary += f"- **{field_name}**: {answers[field_id]}\n"
                info_added = True

        if not info_added:
            summary += "- A칰n no se han recopilado datos espec칤ficos.\n"

        # A침adir par치metros t칠cnicos si existen
        if "parametros_agua" in answers and isinstance(
            answers["parametros_agua"], dict
        ):
            summary += "\n### Par치metros T칠cnicos\n"
            for param, value in answers["parametros_agua"].items():
                summary += f"- **{param}**: {value}\n"

        # Dato interesante relevante
        fact = questionnaire_service.get_random_fact(sector, subsector)
        if fact:
            summary += f"\n*{fact}*\n"

        # Confirmaci칩n y siguiente pregunta
        summary += """
쮼s correcta esta informaci칩n? Si necesita realizar alguna correcci칩n, por favor ind칤quelo.
De lo contrario, continuaremos con las siguientes preguntas para completar su perfil de necesidades.

**PREGUNTA: 쮺onfirma que la informaci칩n anterior es correcta?**
1. S칤, la informaci칩n es correcta
2. No, necesito corregir algo
"""

        return summary

    def _update_questionnaire_state(
        self, conversation: Conversation, user_message: str, response: str
    ) -> None:
        """
        Actualiza el estado del cuestionario basado en la respuesta del usuario y la respuesta generada.
        M칠todo simplificado que detecta avances en el cuestionario.
        """
        state = conversation.questionnaire_state

        # Iniciar cuestionario si no est치 activo
        if not state.active and not state.completed:
            state.active = True

        # Detectar sector/subsector en la respuesta generada o mensaje del usuario
        if not state.sector:
            sectors = ["Industrial", "Comercial", "Municipal", "Residencial"]
            for sector in sectors:
                if (
                    sector.lower() in user_message.lower()
                    or sector.lower() in response.lower()
                ):
                    state.sector = sector
                    state.answers["sector_selection"] = sector
                    break

        if state.sector and not state.subsector:
            # Aqu칤 est치 el cambio, usar el servicio importado directamente:
            subsectors = questionnaire_service.get_subsectors(state.sector)
            for subsector in subsectors:
                if (
                    subsector.lower() in user_message.lower()
                    or subsector.lower() in response.lower()
                ):
                    state.subsector = subsector
                    state.answers["subsector_selection"] = subsector
                    break

        # Detectar finalizaci칩n del cuestionario (si la respuesta contiene una propuesta)
        proposal_indicators = [
            "Propuesta Preliminar",
            "Diagn칩stico Inicial",
            "Tren de Tratamiento",
            "Costos Estimados",
            "CAPEX",
            "OPEX",
            "Beneficios Potenciales",
        ]

        if sum(1 for indicator in proposal_indicators if indicator in response) >= 3:
            state.completed = True
            state.active = False

    def _is_multiple_choice_question(
        self, question_id: str, sector: str, subsector: str
    ) -> bool:
        """
        Determina si una pregunta es de opci칩n m칰ltiple

        Args:
            question_id: ID de la pregunta
            sector: Sector seleccionado
            subsector: Subsector seleccionado

        Returns:
            bool: True si es pregunta de opci칩n m칰ltiple
        """
        if question_id in ["sector_selection", "subsector_selection"]:
            return True

        # Obtener las preguntas para este sector/subsector
        questions_key = f"{sector}_{subsector}"
        questions = questionnaire_service.questionnaire_data.get("questions", {}).get(
            questions_key, []
        )

        for q in questions:
            if q.get("id") == question_id and q.get("type") in [
                "multiple_choice",
                "multiple_select",
            ]:
                return True

        return False

    def _extract_option_from_multiple_choice(
        self, question_id: str, user_message: str, sector: str, subsector: str
    ) -> Optional[str]:
        """
        Extrae la opci칩n seleccionada de una pregunta de opci칩n m칰ltiple

        Args:
            question_id: ID de la pregunta
            user_message: Mensaje del usuario
            sector: Sector seleccionado
            subsector: Subsector seleccionado

        Returns:
            str: Texto de la opci칩n seleccionada o None si no se puede determinar
        """
        # Casos especiales
        if question_id == "sector_selection":
            return self._extract_sector(user_message)
        elif question_id == "subsector_selection":
            return self._extract_subsector(user_message, sector)

        # Obtener opciones para esta pregunta
        questions_key = f"{sector}_{subsector}"
        questions = questionnaire_service.questionnaire_data.get("questions", {}).get(
            questions_key, []
        )

        for q in questions:
            if q.get("id") == question_id and "options" in q:
                options = q["options"]

                # Verificar si es una respuesta num칠rica
                if user_message.strip().isdigit():
                    index = int(user_message.strip()) - 1
                    if 0 <= index < len(options):
                        return options[index]

                # Buscar coincidencia textual
                user_message_lower = user_message.lower()
                for option in options:
                    if option.lower() in user_message_lower:
                        return option

        return None

    def _is_affirmative_response(self, message: str) -> bool:
        """
        Determina si una respuesta es afirmativa

        Args:
            message: Mensaje del usuario

        Returns:
            bool: True si la respuesta es afirmativa
        """
        affirmative_terms = [
            "s칤",
            "si",
            "s",
            "yes",
            "correcto",
            "exacto",
            "cierto",
            "afirmativo",
            "est치 bien",
            "esta bien",
            "confirmo",
            "1",
            "ok",
            "okay",
            "vale",
            "proceder",
        ]

        message_lower = message.lower()

        return any(term in message_lower for term in affirmative_terms)

    def _extract_sector(self, message: str) -> Optional[str]:
        """Extrae el sector industrial de la respuesta del usuario"""
        message = message.lower()
        sectors = ["industrial", "comercial", "municipal", "residencial"]

        # Verificar respuesta num칠rica (1-4)
        if message.strip() in ["1", "2", "3", "4"]:
            index = int(message.strip()) - 1
            if 0 <= index < len(sectors):
                return sectors[index].capitalize()

        # Buscar coincidencia textual
        for sector in sectors:
            if sector in message:
                return sector.capitalize()

        return None

    def _extract_subsector(self, message: str, sector: str) -> Optional[str]:
        """Extrae el subsector de la respuesta del usuario"""
        message = message.lower()

        # Obtener subsectores para el sector seleccionado
        subsectors = questionnaire_service.get_subsectors(sector)

        # Verificar respuesta num칠rica
        if message.strip().isdigit():
            index = int(message.strip()) - 1
            if 0 <= index < len(subsectors):
                return subsectors[index]

        # Buscar coincidencia textual
        for subsector in subsectors:
            if subsector.lower() in message:
                return subsector

        return None

    def _get_next_question(
        self, conversation: Conversation
    ) -> Optional[Dict[str, Any]]:
        """Obtiene la siguiente pregunta seg칰n el estado del cuestionario"""
        state = conversation.questionnaire_state

        # Si no tenemos sector, preguntar por sector
        if not state.sector:
            return {
                "id": "sector_selection",
                "text": "쮼n qu칠 sector opera su empresa?",
                "type": "multiple_choice",
                "options": questionnaire_service.get_sectors(),
                "explanation": "El sector nos ayudar치 a entender mejor su contexto y necesidades espec칤ficas.",
            }

        # Si tenemos sector pero no subsector, preguntar por subsector
        if state.sector and not state.subsector:
            return {
                "id": "subsector_selection",
                "text": f"쮺u치l es el subsector espec칤fico dentro de {state.sector}?",
                "type": "multiple_choice",
                "options": questionnaire_service.get_subsectors(state.sector),
                "explanation": "Cada subsector tiene caracter칤sticas y necesidades espec칤ficas para el tratamiento de agua.",
            }

        # Si estamos en un resumen, preguntar confirmaci칩n
        if state.current_question_id == "confirm_summary":
            return {
                "id": "confirm_summary",
                "text": "쮺onfirma que la informaci칩n proporcionada es correcta?",
                "type": "multiple_choice",
                "options": [
                    "S칤, la informaci칩n es correcta",
                    "No, necesito corregir algo",
                ],
                "explanation": "Es importante verificar que la informaci칩n recopilada sea precisa para dise침ar la mejor soluci칩n para su caso.",
            }

        # Obtener las preguntas para este sector/subsector
        questions_key = f"{state.sector}_{state.subsector}"
        questions = questionnaire_service.questionnaire_data.get("questions", {}).get(
            questions_key, []
        )

        # Encontrar la siguiente pregunta no respondida
        for question in questions:
            if question["id"] not in state.answers:
                return question

        # Si todas las preguntas han sido respondidas, no hay siguiente pregunta
        return None

    def _handle_post_proposal_questions(
        self, conversation: Conversation, user_message: str
    ) -> str:
        """
        Maneja preguntas espec칤ficas despu칠s de presentar la propuesta final

        Args:
            conversation: Conversaci칩n actual
            user_message: Mensaje del usuario

        Returns:
            str: Respuesta a la pregunta post-propuesta
        """
        # Detectar tipo de pregunta
        message_lower = user_message.lower()

        # Preguntas sobre tecnolog칤a
        if any(
            tech in message_lower
            for tech in [
                "tecnolog칤a",
                "tecnologia",
                "sistema",
                "tratamiento",
                "proceso",
                "c칩mo funciona",
                "como funciona",
            ]
        ):
            return """
## Tecnolog칤a de Tratamiento

El sistema propuesto utiliza un enfoque multietapa que incluye:

1. **Pretratamiento**: Elimina s칩lidos gruesos y estabiliza el flujo para un tratamiento 칩ptimo.
2. **Tratamiento primario**: Utiliza procesos f칤sico-qu칤micos para remover s칩lidos suspendidos y compuestos espec칤ficos.
3. **Tratamiento secundario**: Emplea procesos biol칩gicos optimizados para degradar compuestos org치nicos.
4. **Tratamiento terciario**: Aplica filtraci칩n avanzada y desinfecci칩n para conseguir la calidad requerida.

Cada etapa est치 dimensionada espec칤ficamente para sus vol칰menes y caracter칤sticas de agua, maximizando la eficiencia y minimizando costos operativos.

쮿ay alg칰n aspecto espec칤fico de la tecnolog칤a que le gustar칤a conocer con m치s detalle?
"""

        # Preguntas sobre costos
        elif any(
            cost in message_lower
            for cost in [
                "costo",
                "precio",
                "inversi칩n",
                "inversion",
                "financiamiento",
                "financiacion",
                "pagar",
                "econ칩mico",
                "economico",
            ]
        ):
            return """
## Detalles Econ칩micos

La propuesta incluye:

- **Inversi칩n inicial (CAPEX)**: Incluye equipos, instalaci칩n, programaci칩n y puesta en marcha.
- **Costos operativos (OPEX)**: Incluye consumo energ칠tico, qu칤micos, mantenimiento y mano de obra.
- **Retorno de inversi칩n**: Basado en ahorros directos (agua, descargas) e indirectos (cumplimiento, imagen).

Ofrecemos diferentes opciones de financiamiento, incluyendo compra directa, leasing o modalidades de pago por uso (OPEX puro).

El an치lisis detallado del ROI est치 disponible en el documento PDF de la propuesta. 쯃e gustar칤a conocer opciones espec칤ficas de financiamiento para su caso?
"""

        # Preguntas sobre implementaci칩n
        elif any(
            impl in message_lower
            for impl in [
                "implementar",
                "instalar",
                "tiempo",
                "plazo",
                "cuando",
                "cu치ndo",
                "espacio",
                "construcci칩n",
                "construir",
            ]
        ):
            return """
## Implementaci칩n del Sistema

El proceso de implementaci칩n t칤picamente incluye:

1. **Fase de dise침o detallado**: 2-4 semanas
2. **Fabricaci칩n y preparaci칩n**: 6-10 semanas
3. **Instalaci칩n in situ**: 2-4 semanas
4. **Puesta en marcha y ajustes**: 1-2 semanas

El espacio requerido depende de su volumen de agua, pero para su caso estimamos aproximadamente 50-100 m para la instalaci칩n completa.

Nuestro equipo maneja todo el proceso, incluyendo permisos, instalaci칩n y capacitaci칩n de personal. 쯊iene alguna restricci칩n particular de tiempo o espacio para la implementaci칩n?
"""

        # Otras preguntas o comentarios
        else:
            return """
Gracias por su inter칠s en nuestra propuesta. 

Para cualquier otra consulta espec칤fica sobre aspectos t칠cnicos, econ칩micos, de implementaci칩n o mantenimiento, estamos a su disposici칩n. Nuestra propuesta es totalmente personalizable y podemos ajustar cualquier par치metro para satisfacer sus necesidades particulares.

Si desea avanzar con el proyecto, el siguiente paso ser칤a una reuni칩n t칠cnica para afinar detalles y establecer un cronograma de implementaci칩n. Tambi칠n podemos organizar una visita a instalaciones similares para que pueda ver nuestras soluciones en funcionamiento.

쮼n qu칠 otro aspecto podemos ayudarle?
"""

    def _is_pdf_request(self, message: str) -> bool:
        """
        Determina si el mensaje del usuario es una solicitud de PDF con detecci칩n mejorada

        Args:
            message: Mensaje del usuario

        Returns:
            bool: True si es una solicitud de PDF
        """
        message = message.lower()

        # Palabras clave espec칤ficas relacionadas con documentos/PDF
        pdf_keywords = [
            "pdf",
            "descargar",
            "download",
            "propuesta",
            "documento",
            "guardar",
            "archivo",
            "exportar",
            "bajar",
            "obtener",
            "enviar",
            "mandar",
            "recibir",
            "adjuntar",
        ]

        # Frases espec칤ficas de solicitud
        pdf_phrases = [
            "quiero el pdf",
            "dame la propuesta",
            "ver el documento",
            "obtener el archivo",
            "descargar la propuesta",
            "enviame el pdf",
            "generar documento",
            "necesito la propuesta",
            "env칤ame la propuesta",
            "dame el documento",
            "puedo tener",
            "puedo obtener",
            "me gustar칤a el pdf",
            "puedes enviarme",
            "necesito descargar",
            "puedo descargar",
            "el enlace no funciona",
        ]

        # Detectar palabras clave individuales
        if any(keyword in message for keyword in pdf_keywords):
            return True

        # Detectar frases espec칤ficas
        for phrase in pdf_phrases:
            if phrase in message:
                return True

        # Detectar patrones de pregunta sobre el documento
        if any(
            pattern in message
            for pattern in [
                "como obtengo",
                "c칩mo descargo",
                "donde est치",
                "d칩nde puedo",
                "link de",
                "enlace para",
            ]
        ):
            if any(
                doc_word in message
                for doc_word in ["pdf", "documento", "propuesta", "informe"]
            ):
                return True

        return False

    def generate_subsector_question(self, sector: str) -> str:
        """
        Genera la pregunta para seleccionar el subsector basado en el sector elegido

        Args:
            sector: Sector seleccionado

        Returns:
            str: Pregunta formateada sobre el subsector
        """
        subsector_options = questionnaire_service.get_subsectors(sector)
        interesting_fact = questionnaire_service.get_random_fact(sector)

        return self.format_response_with_questions(
            f"Gracias por indicar que opera en el sector {sector}. Esto nos permite entender el contexto general de sus necesidades de tratamiento de agua.",
            interesting_fact,
            "Cada subsector tiene caracter칤sticas y necesidades espec칤ficas para el tratamiento de agua. Identificar su subsector nos permitir치 personalizar a칰n m치s la soluci칩n.",
            f"쮺u치l es el subsector espec칤fico dentro de {sector}?",
            subsector_options,
        )

    def _safe_extract_from_response(
        self, user_message: str, default_value: Any = None
    ) -> Any:
        """
        Extrae informaci칩n de una respuesta del usuario de forma segura,
        manejando posibles errores

        Args:
            user_message: Mensaje del usuario
            default_value: Valor por defecto si no se puede extraer informaci칩n

        Returns:
            Any: Informaci칩n extra칤da o valor por defecto
        """
        try:
            # Intentar extraer informaci칩n
            # Implementaci칩n espec칤fica seg칰n el contexto
            return extracted_value
        except Exception as e:
            logger.warning(f"Error al extraer informaci칩n de respuesta: {e}")
            return default_value

    def _validate_questionnaire_state(self, conversation: Conversation) -> bool:
        """
        Valida que el estado del cuestionario sea consistente
        y recupera errores cuando sea posible

        Args:
            conversation: Conversaci칩n actual

        Returns:
            bool: True si el estado es v치lido, False en caso contrario
        """
        state = conversation.questionnaire_state

        # Verificar consistencia b치sica
        if (
            state.active
            and not state.sector
            and state.current_question_id != "sector_selection"
        ):
            # Inconsistencia: cuestionario activo sin sector y no estamos preguntando por sector
            logger.warning("Inconsistencia detectada: cuestionario activo sin sector")

            # Corregir el estado
            state.current_question_id = "sector_selection"
            return False

        if (
            state.active
            and state.sector
            and not state.subsector
            and state.current_question_id != "subsector_selection"
        ):
            # Inconsistencia: tenemos sector pero no subsector y no estamos preguntando por subsector
            logger.warning("Inconsistencia detectada: falta subsector")

            # Corregir el estado
            state.current_question_id = "subsector_selection"
            return False

        return True

    async def handle_conversation(
        self, conversation: Conversation, user_message: str
    ) -> str:
        """
        M칠todo simplificado que aprovecha las capacidades inherentes del modelo
        en lugar de intentar replicarlas con l칩gica compleja.
        """
        try:
            # Si el cuestionario est치 completado y el usuario pide el PDF
            if conversation.is_questionnaire_completed() and self._is_pdf_request(
                user_message
            ):
                download_url = f"/api/chat/{conversation.id}/download-proposal-pdf"
                return f"""
# 游늯 Propuesta Lista para Descargar

He preparado su propuesta personalizada basada en la informaci칩n proporcionada. Puede descargarla como PDF usando el siguiente enlace:

## [游녤 DESCARGAR PROPUESTA EN PDF]({download_url})

Este documento incluye:
- An치lisis de sus necesidades espec칤ficas
- Soluci칩n tecnol칩gica recomendada
- Estimaci칩n de costos y retorno de inversi칩n
- Pasos siguientes recomendados

쯅ecesita alguna aclaraci칩n sobre la propuesta o tiene alguna otra pregunta?
"""

            # Construir mensajes para la API
            messages = [
                {"role": "system", "content": settings.SYSTEM_PROMPT},
            ]

            # A침adir informaci칩n de contexto actual como parte del sistema
            if (
                conversation.questionnaire_state.sector
                or conversation.questionnaire_state.subsector
            ):
                context_info = "Informaci칩n de contexto:\n"
                if conversation.questionnaire_state.sector:
                    context_info += f"- Sector identificado: {conversation.questionnaire_state.sector}\n"
                if conversation.questionnaire_state.subsector:
                    context_info += (
                        f"- Subsector: {conversation.questionnaire_state.subsector}\n"
                    )

                # A침adir informaci칩n de respuestas clave si existen
                answers = conversation.questionnaire_state.answers
                key_answers = []

                if "nombre_empresa" in answers:
                    key_answers.append(
                        f"- Nombre empresa/usuario: {answers['nombre_empresa']}"
                    )
                if "ubicacion" in answers:
                    key_answers.append(f"- Ubicaci칩n: {answers['ubicacion']}")
                if "costo_agua" in answers:
                    key_answers.append(f"- Costo agua: {answers['costo_agua']}")
                if "cantidad_agua_consumida" in answers:
                    key_answers.append(
                        f"- Consumo agua: {answers['cantidad_agua_consumida']}"
                    )

                if key_answers:
                    context_info += "\nDatos proporcionados:\n" + "\n".join(key_answers)

                messages.append({"role": "system", "content": context_info})

            # A침adir todo el historial de conversaci칩n relevante
            for msg in conversation.messages:
                if msg.role in [
                    "user",
                    "assistant",
                ]:  # Solo incluir mensajes de usuario y asistente
                    messages.append({"role": msg.role, "content": msg.content})

            # Dejar que el modelo genere la respuesta completa
            response = await self.generate_response(messages)

            # Actualizar el estado del cuestionario basado en la respuesta generada
            self._update_questionnaire_state(conversation, user_message, response)

            return response

        except Exception as e:
            logger.error(f"Error en handle_conversation: {str(e)}")
            return "Lo siento, ha ocurrido un error al procesar su consulta. Por favor, int칠ntelo de nuevo."

    async def generate_response(
        self,
        messages: List[Dict[str, Any]],
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
    ) -> str:
        """
        Genera una respuesta utilizando el proveedor de IA configurado

        Args:
            messages: Lista de mensajes para la conversaci칩n
            temperature: Temperatura para la generaci칩n (0.0-1.0)
            max_tokens: N칰mero m치ximo de tokens para la respuesta

        Returns:
            str: Texto de la respuesta generada con formato adecuado para el frontend
        """
        try:
            # Verificar si tenemos conexi칩n con la API
            if not self.api_key or not self.api_url:
                return self._get_fallback_response(messages)

            # Hacer solicitud a la API
            async with httpx.AsyncClient() as client:
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.api_key}",
                }

                payload = {
                    "model": self.model,
                    "messages": messages,
                    "temperature": temperature,
                    "max_tokens": max_tokens or 1024,
                }

                response = await client.post(
                    self.api_url, json=payload, headers=headers, timeout=30.0
                )

                if response.status_code != 200:
                    logger.error(
                        f"Error en la API de {self.provider}: {response.status_code} - {response.text}"
                    )
                    return self._get_fallback_response(messages)

                response_data = response.json()
                raw_response = response_data["choices"][0]["message"]["content"]

                # Procesar el texto para mantener un formato consistente
                processed_response = self._process_response_format(raw_response)

                return processed_response

        except Exception as e:
            logger.error(f"Error al generar respuesta con {self.provider}: {str(e)}")
            return self._get_fallback_response(messages)

    def _process_response_format(self, text: str) -> str:
        """
        Procesa el texto de respuesta para asegurar un formato adecuado para el frontend

        Args:
            text: Texto original de la respuesta

        Returns:
            str: Texto procesado con formato adecuado
        """
        # No realizamos modificaciones al texto, permitiendo el uso completo de Markdown
        # Solo realizamos algunas mejoras menor para garantizar formato consistente

        # Asegurar que los enlaces Markdown esten correctamente formateados
        text = re.sub(r"\[([^\]]+)\]\s*\(([^)]+)\)", r"[\1](\2)", text)

        # Asegurar que los encabezados tengan espacio despues del #
        for i in range(6, 0, -1):  # de h5 a h1
            heading = "#" * i
            text = re.sub(
                f"^{heading}([^#\s])", f"{heading} \\1", text, flags=re.MULTILINE
            )

        return text

    def _get_fallback_response(self, messages: List[Dict[str, Any]]) -> str:
        """
        Genera una respuesta de fallback cuando no podemos conectar con la API

        Args:
            messages: Lista de mensajes para intentar determinar una respuesta contextual

        Returns:
            str: Texto de respuesta pre-configurada
        """
        # Intentar obtener el 칰ltimo mensaje del usuario
        last_user_message = ""
        for msg in reversed(messages):
            if msg.get("role") == "user":
                last_user_message = msg.get("content", "").lower()
                break

        # Respuestas pre-configuradas seg칰n palabras clave
        if (
            "hola" in last_user_message
            or "saludos" in last_user_message
            or not last_user_message
        ):
            return (
                "춰Hola! Soy el Dise침ador de Soluciones de Agua con IA de Hydrous, especializado en soluciones de reciclaje de agua. "
                "쮼n qu칠 puedo ayudarte hoy?"
            )

        elif any(
            word in last_user_message
            for word in ["filtro", "filtraci칩n", "purificaci칩n"]
        ):
            return (
                "Nuestros sistemas de filtraci칩n avanzada eliminan contaminantes, sedimentos y pat칩genos "
                "del agua. Utilizamos tecnolog칤a de membranas, carb칩n activado y filtros biol칩gicos para "
                "adaptarnos a diferentes necesidades. 쯊e gustar칤a m치s informaci칩n sobre alg칰n sistema espec칤fico?"
            )

        elif any(
            word in last_user_message for word in ["aguas grises", "duchas", "lavadora"]
        ):
            return (
                "Nuestros sistemas de tratamiento de aguas grises reciclan el agua de duchas, lavabos y lavadoras "
                "para su reutilizaci칩n en inodoros, riego o limpieza. Son modulares y se adaptan a diferentes "
                "espacios. 쯅ecesitas informaci칩n para un proyecto residencial o comercial?"
            )

        else:
            return (
                "Gracias por tu pregunta. Para brindarte la mejor soluci칩n de reciclaje de agua, "
                "te recomendar칤a completar nuestro cuestionario personalizado. As칤 podr칠 entender "
                "mejor tus necesidades espec칤ficas. 쯊e gustar칤a comenzar?"
            )


# Clase extendida del servicio de IA (se utilizar치 en lugar de la est치ndar)
class AIWithQuestionnaireService(AIService):
    """Versi칩n del servicio de IA con funcionalidad de cuestionario integrada"""

    def __init__(self):
        super().__init__()
        # Inicializar el seguimiento de estado de las conversaciones
        self.conversation_states = {}

    # Los m칠todos de AIService b치sico ya est치n heredados
    # Aqu칤 solo implementamos m칠todos adicionales o sobreescribimos cuando sea necesario

    # M칠todo para completar flujo de cuestionario
    def complete_questionnaire(self, conversation: Conversation) -> None:
        """Marca el cuestionario como completado y actualiza el estado"""
        conversation_id = conversation.id
        if conversation_id in self.conversation_states:
            self.conversation_states[conversation_id]["current_stage"] = "PROPOSAL"
            self.conversation_states[conversation_id]["ready_for_proposal"] = True

        # Actualizar tambi칠n el estado en el objeto conversaci칩n
        conversation.complete_questionnaire()

    def _handle_post_proposal_questions(
        self, conversation: Conversation, user_message: str
    ) -> str:
        """
        Maneja preguntas o solicitudes despu칠s de generar la propuesta

        Args:
            conversation: Conversaci칩n actual
            user_message: Mensaje del usuario

        Returns:
            str: Respuesta personalizada
        """
        # Detectar tipo de pregunta/solicitud
        message_lower = user_message.lower()

        # Solicitud de explicaci칩n t칠cnica
        if any(
            term in message_lower
            for term in [
                "explicar",
                "detallar",
                "c칩mo funciona",
                "tecnolog칤a",
                "proceso",
            ]
        ):
            return self._generate_technical_explanation(conversation)

        # Solicitud de informaci칩n de costos
        elif any(
            term in message_lower
            for term in ["costo", "precio", "inversi칩n", "financiamiento", "pago"]
        ):
            return self._generate_cost_explanation(conversation)

        # Solicitud sobre plazos
        elif any(
            term in message_lower
            for term in ["tiempo", "plazo", "cu치ndo", "implementaci칩n", "instalaci칩n"]
        ):
            return self._generate_timeline_explanation(conversation)

        # Solicitud sobre personalizaci칩n
        elif any(
            term in message_lower
            for term in ["modificar", "cambiar", "ajustar", "personalizar"]
        ):
            return self._generate_customization_explanation(conversation)

        # Si no es ninguna de las anteriores, respuesta general
        return """
Gracias por su inter칠s en nuestra propuesta. Estar칠 encantado de aclarar cualquier duda o proporcionar informaci칩n adicional sobre los aspectos t칠cnicos, costos, plazos de implementaci칩n o cualquier ajuste que desee realizar.

La propuesta que ha recibido es preliminar y puede personalizarse seg칰n sus necesidades espec칤ficas. 쮿ay alg칰n aspecto particular sobre el que desear칤a m치s detalles?

1. Detalles t칠cnicos del sistema propuesto
2. Informaci칩n sobre costos y financiamiento
3. Plazos de implementaci칩n y fases del proyecto
4. Opciones de personalizaci칩n o ajustes a la soluci칩n
5. Requisitos de mantenimiento y operaci칩n
"""

    def _generate_technical_explanation(self, conversation: Conversation) -> str:
        """Genera una explicaci칩n t칠cnica detallada del sistema propuesto"""

        state = conversation.questionnaire_state
        sector = state.sector
        subsector = state.subsector

        explanation = f"""
## Detalles T칠cnicos del Sistema Propuesto

El sistema de tratamiento dise침ado para su operaci칩n {sector} - {subsector} consta de varias etapas interconectadas, cada una con un prop칩sito espec칤fico:

### 1. Pretratamiento
"""

        # Personalizar seg칰n sector/subsector
        if subsector == "Textil":
            explanation += """
El agua residual primero pasa por un sistema de cribado autom치tico para remover fibras y part칤culas grandes, seguido de un tanque de homogeneizaci칩n con agitaci칩n que equilibra los picos de caudal y concentraci칩n, especialmente importantes en la industria textil donde los lotes de producci칩n pueden variar significativamente.

### 2. Tratamiento Primario
Se implementa un sistema de Flotaci칩n por Aire Disuelto (DAF) con dosificaci칩n de coagulantes espec칤ficos para colorantes, que puede remover hasta el 95% de los colorantes y 85% de los s칩lidos suspendidos. Esta etapa es crucial para la industria textil debido a la alta carga de colorantes.

### 3. Tratamiento Secundario
Utilizamos un Reactor de Biopel칤cula de Lecho M칩vil (MBBR) con microorganismos especializados en degradar compuestos org치nicos recalcitrantes t칤picos de la industria textil. Esta tecnolog칤a requiere menos espacio que los lodos activados convencionales mientras proporciona mayor eficiencia.

### 4. Tratamiento Terciario
El sistema incluye filtraci칩n por carb칩n activado para eliminar colorantes residuales y compuestos org치nicos, seguido de desinfecci칩n UV que no genera subproductos indeseables.
"""
        elif subsector == "Alimentos y Bebidas":
            explanation += """
El agua residual primero pasa por un sistema de cribado seguido de una trampa de grasas y aceites de alto rendimiento, cr칤tica para la industria alimentaria, que puede remover hasta un 95% de grasas y aceites.

### 2. Tratamiento Primario
Se implementa un sistema de coagulaci칩n/floculaci칩n optimizado para materia org치nica de origen alimenticio, seguido de sedimentaci칩n acelerada que reduce significativamente la carga org치nica.

### 3. Tratamiento Secundario
Se utiliza un sistema combinado anaerobio-aerobio, comenzando con un reactor UASB (Upflow Anaerobic Sludge Blanket) que adem치s de tratar el agua genera biog치s aprovechable energ칠ticamente, seguido de un sistema de lodos activados de alta eficiencia.

### 4. Tratamiento Terciario
El sistema incluye filtraci칩n multimedia y desinfecci칩n UV para garantizar la calidad microbiol칩gica del efluente, fundamental en la industria alimentaria.
"""
        else:
            # Versi칩n gen칠rica para otros sectores
            explanation += """
El agua residual primero pasa por sistemas de cribado y homogeneizaci칩n adaptados a su caudal espec칤fico, dise침ados para manejar las variaciones propias de su operaci칩n.

### 2. Tratamiento Primario
Se implementa un sistema f칤sico-qu칤mico personalizado para los contaminantes espec칤ficos de su sector, garantizando alta eficiencia en la remoci칩n de s칩lidos y contaminantes clave.

### 3. Tratamiento Secundario
Utilizamos un sistema biol칩gico optimizado para la biodegradabilidad espec칤fica de sus contaminantes, con dise침o modular que permite ajustar la capacidad seg칰n sus necesidades.

### 4. Tratamiento Terciario
El sistema incluye etapas de pulido final adaptadas a sus objetivos de re칰so o descarga, garantizando el cumplimiento de los par치metros requeridos.
"""

        explanation += """
### Caracter칤sticas Adicionales del Sistema

- **Control automatizado**: Todo el sistema est치 equipado con sensores y controladores que permiten un funcionamiento 칩ptimo con m칤nima intervenci칩n humana.
- **M칩dulos de telemetr칤a**: Permiten el monitoreo remoto y alertas en tiempo real para garantizar un funcionamiento constante.
- **Dise침o modular**: Facilita futuras ampliaciones o modificaciones seg칰n evolucionen sus necesidades.
- **Eficiencia energ칠tica**: Incorpora variadores de frecuencia y sistemas de recuperaci칩n de energ칤a donde es aplicable.

쮻esea informaci칩n adicional sobre alguna etapa espec칤fica del tratamiento o alguna tecnolog칤a en particular?
"""

        return explanation

    def _generate_cost_explanation(self, conversation: Conversation) -> str:
        """Genera una explicaci칩n detallada sobre costos y financiamiento"""

        # Extraer informaci칩n econ칩mica si existe
        proposal = None
        try:
            proposal = questionnaire_service.generate_proposal(conversation)
        except:
            pass

        economic = proposal.get("economic_analysis", {}) if proposal else {}
        capex = economic.get("capex", 100000)
        opex_monthly = economic.get("opex_monthly", 2000)
        roi = economic.get("roi", 3)

        explanation = f"""
## Informaci칩n Detallada sobre Costos e Inversi칩n

### Estructura de Costos

La inversi칩n en el sistema de tratamiento propuesto se divide en:

1. **Inversi칩n inicial (CAPEX)**: Aproximadamente USD ${capex:,.2f}
   - Equipamiento: 60-65% del CAPEX
   - Obra civil e instalaci칩n: 25-30% del CAPEX
   - Ingenier칤a y puesta en marcha: 10-15% del CAPEX

2. **Costos operativos mensuales (OPEX)**: Aproximadamente USD ${opex_monthly:,.2f}/mes
   - Consumo energ칠tico: 30-35% del OPEX
   - Qu칤micos y consumibles: 20-25% del OPEX
   - Mantenimiento preventivo: 15-20% del OPEX
   - Personal operativo: 25-30% del OPEX

### Retorno de la Inversi칩n (ROI)

Con base en la informaci칩n proporcionada, estimamos un periodo de recuperaci칩n de inversi칩n de aproximadamente {roi:.1f} a침os, considerando:

- Ahorro en compra de agua fresca
- Reducci칩n en costos de descarga
- Menor riesgo de multas ambientales
- Posible valorizaci칩n de subproductos

### Opciones de Financiamiento

Hydrous Management Group colabora con diversas instituciones financieras que ofrecen opciones espec칤ficas para proyectos de sostenibilidad:

1. **Leasing de equipos**: Permite distribuir el costo a lo largo de 3-5 a침os
2. **Financiamiento verde**: Tasas preferenciales para proyectos ambientales
3. **Esquema BOT (Build-Operate-Transfer)**: Hydrous construye y opera el sistema inicialmente
4. **Pagos por desempe침o**: Estructuraci칩n de pagos basados en resultados y ahorros obtenidos

쮻esea informaci칩n m치s espec칤fica sobre alguna opci칩n de financiamiento o un desglose m치s detallado de costos?
"""

        return explanation

    def _generate_timeline_explanation(self, conversation: Conversation) -> str:
        """Genera una explicaci칩n sobre los plazos de implementaci칩n"""

        explanation = """
## Plazos de Implementaci칩n del Proyecto

El desarrollo e implementaci칩n de su sistema de tratamiento de agua se estructura en las siguientes fases:

### Fase 1: Ingenier칤a de Detalle (4-6 semanas)
- Caracterizaci칩n detallada del agua residual
- Dimensionamiento preciso de equipos
- Dise침o de planos constructivos
- Desarrollo de P&ID (Diagramas de Tuber칤as e Instrumentaci칩n)

### Fase 2: Adquisici칩n y Fabricaci칩n (8-12 semanas)
- Procura de equipos principales
- Fabricaci칩n de componentes especializados
- Control de calidad en f치brica
- Preparaci칩n del sitio para instalaci칩n

### Fase 3: Instalaci칩n y Montaje (4-6 semanas)
- Obra civil (si es requerida)
- Montaje de equipos
- Interconexi칩n de sistemas
- Instalaci칩n el칠ctrica y automatizaci칩n

### Fase 4: Puesta en Marcha (3-4 semanas)
- Pruebas hidr치ulicas
- Arranque secuencial de procesos
- Inoculaci칩n de sistemas biol칩gicos
- Ajuste de par치metros operativos

### Fase 5: Capacitaci칩n y Entrega (2 semanas)
- Entrenamiento del personal operativo
- Entrega de manuales y documentaci칩n
- Establecimiento de rutinas de mantenimiento
- Validaci칩n de par치metros de calidad del agua

**Tiempo total estimado: 21-30 semanas** (5-7 meses)

Existe la posibilidad de implementar un enfoque modular o por etapas si se requiere una puesta en operaci칩n m치s r치pida de ciertas partes del sistema.

쯃e interesa alguna opci칩n para acelerar la implementaci칩n o tiene requerimientos particulares de tiempos para alguna etapa espec칤fica?
"""

        return explanation

    def _generate_customization_explanation(self, conversation: Conversation) -> str:
        """Genera una explicaci칩n sobre opciones de personalizaci칩n"""

        state = conversation.questionnaire_state
        sector = state.sector
        subsector = state.subsector

        explanation = f"""
## Opciones de Personalizaci칩n de la Soluci칩n

La propuesta presentada puede adaptarse seg칰n sus necesidades espec칤ficas. Estas son las principales 치reas donde podemos realizar ajustes:

### Capacidad y Dimensionamiento
- **Escalamiento modular**: Implementaci칩n por fases para distribuir la inversi칩n
- **Modificaci칩n de capacidad**: Ajuste del dimensionamiento seg칰n proyecciones de crecimiento
- **Redundancia de sistemas**: Incorporaci칩n de equipos de respaldo en componentes cr칤ticos

### Tecnolog칤as Alternativas
"""

        # Opciones espec칤ficas seg칰n el sector/subsector
        if subsector == "Textil":
            explanation += """
- **Tratamiento de color**: Alternativas como ozono, procesos electroqu칤micos o adsorci칩n avanzada
- **Manejo de salinidad**: Incorporaci칩n de tecnolog칤as de membrana si la conductividad es un par치metro cr칤tico
- **Recuperaci칩n de calor**: Sistemas para aprovechar la energ칤a t칠rmica del agua residual
"""
        elif subsector == "Alimentos y Bebidas":
            explanation += """
- **Recuperaci칩n de subproductos**: Sistemas para extraer materiales valorizables presentes en el agua
- **Maximizaci칩n del biog치s**: Tecnolog칤as avanzadas para optimizar la generaci칩n energ칠tica
- **Tratamiento de alta carga**: Opciones para manejar picos estacionales de producci칩n
"""
        else:
            explanation += """
- **Tecnolog칤as espec칤ficas**: Soluciones adaptadas a contaminantes particulares de su industria
- **Sistemas compactos**: Alternativas para minimizar el espacio requerido
- **Soluciones h칤bridas**: Combinaci칩n de diferentes tecnolog칤as para optimizar resultados
"""

        explanation += """
### Automatizaci칩n y Control
- **Nivel de automatizaci칩n**: Desde sistemas b치sicos hasta completamente automatizados
- **Integraci칩n con sistemas existentes**: Compatibilidad con plataformas SCADA o ERP actuales
- **Monitoreo remoto**: Diferentes niveles de telemetr칤a y control a distancia

### Modelos de Servicio
- **Mantenimiento**: Opciones desde capacitaci칩n a personal propio hasta contratos de servicio integral
- **Modelos de operaci칩n**: Posibilidad de contrato BOT (Build-Operate-Transfer) o servicio por volumen tratado
- **Garant칤as extendidas**: Ampliaci칩n de coberturas y plazos seg칰n sus necesidades

쮿ay alg칰n aspecto espec칤fico de la soluci칩n propuesta que le gustar칤a personalizar o alguna restricci칩n particular que debamos considerar?
"""

        return explanation

    def _validate_critical_answer(self, question_id: str, answer: str) -> Optional[str]:
        """
        Valida si la respuesta a una pregunta cr칤tica es adecuada.
        Devuelve un mensaje de insistencia si es necesario, o None si la respuesta es v치lida.
        """

        if question_id not in CRITICAL_QUESTIONS:
            return None

        if not answer or not CRITICAL_QUESTIONS[question_id]["validation"](answer):
            explanation = CRITICAL_QUESTIONS[question_id]["explanation"]
            fallback = CRITICAL_QUESTIONS[question_id]["fallback"]

            return (
                f"Entiendo que puede ser dif칤cil proporcionar este dato con exactitud, pero {explanation}. "
                f"Si no tienes el dato exacto, {fallback}. Esta informaci칩n nos permitir치 "
                f"dise침ar una soluci칩n mucho m치s precisa y adaptada a tus necesidades reales."
            )

        return None

    def _detect_user_type(self, conversation: Conversation) -> str:
        """
        Detecta si el usuario es profesiona, semi-profesional o no profesional
        basado en su lenguaje y conocimientos t칠cnicos
        """
        # Extraer todos los mensajes del usuario
        user_messages = " ".join(
            [msg.content for msg in conversation.messages if msg.role == "user"]
        )

        # Indicadores de usuario profesional
        professional_indicators = [
            "lps",
            "m3/d칤a",
            "DQO",
            "DBO",
            "SST",
            "conductividad",
            "pH",
            "칩smosis",
            "MBBR",
            "MBR",
            "DAF",
            "efluente",
            "PTAR",
            "coagulaci칩n",
            "NOM-",
            "reactor",
            "anaerobio",
            "biol칩gico",
            "cumplimiento normativo",
            "par치metros t칠cnicos",
        ]

        # Indicadores de semi-profesional
        semi_indicators = [
            "tratamiento",
            "litros por segundo",
            "metros c칰bicos",
            "agua residual",
            "filtraci칩n",
            "norma",
            "agua industrial",
            "descarga",
            "reutilizaci칩n",
            "bombas",
            "tanques",
            "sistema",
            "automatizaci칩n",
        ]

        # Contar Indicadores
        prof_count = sum(
            1
            for term in professional_indicators
            if term.lower() in user_messages.lower()
        )

        semi_count = sum(
            1 for term in semi_indicators if term.lower() in user_messages.lower()
        )

        # Clasificar usuario
        if prof_count >= 3:
            return "professional"
        elif semi_count >= 3 or prof_count >= 1:
            return "semi-profesional"
        else:
            return "non-professional"

    def _format_positive_validation(self, previous_message: str) -> str:
        """
        Genera una validaci칩n positiva personalizada basada en la respuesta anterior.
        """
        validations = [
            "춰Excelente! Gracias por compartir esta informaci칩n.",
            "춰Perfecto! Estos datos son muy valiosos para dise침ar tu soluci칩n.",
            "Gracias por proporcionarnos este detalle importante.",
            "Muy bien. Esta informaci칩n nos ayuda a entender mejor tus necesidades.",
            "춰Genial! Con estos datos avanzamos significativamente en el dise침o de tu soluci칩n.",
        ]

        # Seleccionar una validaci칩n aleatoria, se podr칤a mejorar para que sea m치s contextual
        import random

        return random.choice(validations)

    # Mejorar la selecci칩n de emojis seg칰n el tipo de pregunta
    def _select_emoji_for_question_type(self, question_id: str) -> str:
        """
        Selecciona un emoji apropiado seg칰n el tipo de pregunta.
        """
        emoji_map = {
            "nombre_empresa": "游끽",
            "ubicacion": "游늸",
            "costo_agua": "游눯",
            "cantidad_agua_consumida": "游뛇",
            "cantidad_agua_residual": "游눦",
            "num_personas": "游논",
            "parametros_agua": "游댧",
            "usos_agua": "游댃",
            "fuente_agua": "游깱",
            "objetivo_principal": "游꿢",
            "objetivo_reuso": "鮫勇",
            "descarga_actual": "游닋",
            "restricciones": "丘멆잺",
            "sistema_existente": "丘뙖잺",
            "presupuesto": "游눳",
            "tiempo_proyecto": "낌勇",
            "sector_selection": "游낈",
            "subsector_selection": "游댌",
        }

        return emoji_map.get(question_id, "游늶")

    def _optimize_context_length(
        self, conversation: Conversation
    ) -> List[Dict[str, str]]:
        """
        Optimiza el contexto de la conversaci칩n para manejar conversaciones largas

        Args:
            conversation: Conversaci칩n actual

        Returns:
            List: Lista optimizada de mensajes para el contexto
        """
        messages = []

        # Siempre incluir el mensaje del sistema
        system_messages = [msg for msg in conversation.messages if msg.role == "system"]
        if system_messages:
            messages.append({"role": "system", "content": system_messages[0].content})

        # Si el cuestionario est치 activo, priorizar informaci칩n relevante
        if conversation.is_questionnaire_active():
            # Incluir el 칰ltimo intercambio completo (3-4 mensajes)
            recent_exchanges = [
                msg
                for msg in conversation.messages[-6:]
                if msg.role in ["user", "assistant"]
            ]
            messages.extend(
                [{"role": msg.role, "content": msg.content} for msg in recent_exchanges]
            )

            # A침adir resumen del estado actual
            state = conversation.questionnaire_state
            state_summary = f"""
    Informaci칩n recopilada hasta ahora:
    - Sector: {state.sector}
    - Subsector: {state.subsector}
    - Preguntas respondidas: {state.questions_answered}
    - Pregunta actual: {state.current_question_id}
    """
            messages.append({"role": "system", "content": state_summary})
        else:
            # Para conversaciones normales, incluir mensajes recientes
            recent_messages = [
                msg
                for msg in conversation.messages[-8:]
                if msg.role in ["user", "assistant"]
            ]
            messages.extend(
                [{"role": msg.role, "content": msg.content} for msg in recent_messages]
            )

        return messages


# Instancia global del servicio
ai_service = AIWithQuestionnaireService()
