# app/services/ai_service.py
import logging
import httpx
from typing import List, Dict, Any

from app.config import settings
from app.models.conversation import Conversation
from app.prompts.main_prompt import get_master_prompt

logger = logging.getLogger("hydrous")


class AIService:
    """Servicio simplificado para interactuar con LLMs"""

    def __init__(self):
        """Inicializaci칩n del servicio AI"""
        # Cargar el prompt maestro
        self.master_prompt = get_master_prompt()

        # Configuraci칩n de API
        self.api_key = settings.API_KEY
        self.model = settings.MODEL
        self.api_url = settings.API_URL

    async def handle_conversation(
        self, conversation: Conversation, user_message: str = None
    ) -> str:
        """
        Maneja una conversaci칩n y genera una respuesta
        """
        try:
            # Preparar los mensajes para la API
            messages = self._prepare_messages(conversation, user_message)

            # Llamar a la API del LLM
            response = await self._call_llm_api(messages)

            # Detectar si el mensaje contiene una propuesta completa
            if self._contains_proposal_markers(response):
                conversation.metadata["has_proposal"] = True

            return response

        except Exception as e:
            logger.error(f"Error en handle_conversation: {str(e)}")
            return "Lo siento, ha ocurrido un error al procesar tu consulta. Por favor, int칠ntalo de nuevo."

    def _prepare_messages(self, conversation: Conversation, user_message: str = None):
        # Mensaje sistema base con el prompt maestro optimizado
        messages = [{"role": "system", "content": self.master_prompt}]

        # Detectar fase actual e informaci칩n clave
        message_count = sum(1 for m in conversation.messages if m.role == "user")
        need_summary = message_count > 0 and message_count % 5 == 0

        # Si es momento de hacer resumen, a침adir instrucci칩n espec칤fica
        if need_summary:
            summary_instruction = {
                "role": "system",
                "content": "Antes de hacer la siguiente pregunta, proporciona un BREVE RESUMEN de la informaci칩n clave recopilada hasta ahora. Luego contin칰a con la siguiente pregunta del cuestionario.",
            }
            messages.append(summary_instruction)

        # Si hemos detectado un posible sector, ajustar instrucciones
        if "sector" in conversation.metadata:
            sector = conversation.metadata["sector"]
            sector_instruction = {
                "role": "system",
                "content": f"El usuario pertenece al sector {sector}. Utiliza los datos educativos espec칤ficos para este sector.",
            }
            messages.append(sector_instruction)

        # A침adir mensaje final de recordatorio de estructura
        structure_reminder = {
            "role": "system",
            "content": "RECUERDA: Tu pr칩xima respuesta DEBE seguir la estructura exacta: 1) Validaci칩n positiva, 2) Comentario espec칤fico, 3) Dato educativo con emoji 游눠, 4) Explicaci칩n breve, 5) UNA SOLA pregunta en negrita.",
        }
        messages.append(structure_reminder)

        # A침adir historial de conversaci칩n (limitado)
        for msg in conversation.messages[-12:]:
            if msg.role != "system":
                messages.append({"role": msg.role, "content": msg.content})

        # A침adir nuevo mensaje si existe
        if user_message:
            messages.append({"role": "user", "content": user_message})

        return messages

    def _get_phase_instructions(self, phase, conversation):
        """Genera instrucciones especificas, segun la fase"""
        if phase == "initial_questions":
            return "Estas en la fase inicial de recopilacion de informaci칩n. Concentrate en preguntas basicas sobre la empresa, ubicacion y conusmo de agua"

        elif phase == "detailed_questions":
            # Es momento de hacer un resumen si hay suficiente informaci칩n
            questions_answered = sum(
                1 for msg in conversation.messages if msg.role == "user"
            )
            if questions_answered % 5 == 0 and questions_answered > 0:
                return """
                Haz un breve resumen de la informaci칩n recopilada hasta ahora antes de hacer la siguiente pregunta.
                El resumen debe ser conciso y destacar los puntos clave que has aprendido sobre el proyecto.
                """
            return "Contin칰a con las preguntas detalladas sobre procesos espec칤ficos de agua."

        elif phase == "final_questions":
            return "Est치s en las preguntas finales. Prioriza preguntas sobre restricciones, objetivos principales y plazos."

        elif phase == "proposal_generation":
            return """
            Has recopilado suficiente informaci칩n. Genera una propuesta completa siguiendo el formato establecido:
            1. T칤tulo con nombre del cliente
            2. Antecedentes del proyecto
            3. Objetivos
            4. Par치metros de dise침o
            5. Proceso de tratamiento propuesto
            6. Capacidades estimadas
            7. Costos estimados
            8. An치lisis ROI
            9. Siguientes pasos
            """

        else:  # proposal_complete
            return "El usuario ya tiene una propuesta completa. Responde a sus preguntas adicionales o aclaraciones."

    async def _call_llm_api(self, messages: List[Dict[str, str]]) -> str:
        """Llama a la API del LLM"""
        try:
            # Llamar a la API usando httpx
            async with httpx.AsyncClient() as client:
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.api_key}",
                }

                payload = {
                    "model": self.model,
                    "messages": messages,
                    "temperature": 0.7,
                    "max_tokens": 1500,
                }

                response = await client.post(
                    self.api_url, json=payload, headers=headers, timeout=30.0
                )

                if response.status_code == 200:
                    data = response.json()
                    content = data["choices"][0]["message"]["content"]
                    return content
                else:
                    logger.error(
                        f"Error en API LLM: {response.status_code} - {response.text}"
                    )
                    return "Lo siento, ha habido un problema con el servicio. Por favor, int칠ntalo de nuevo m치s tarde."

        except Exception as e:
            logger.error(f"Error en _call_llm_api: {str(e)}")
            return "Lo siento, ha ocurrido un error al comunicarse con el servicio. Por favor, int칠ntalo de nuevo."

    def _contains_proposal_markers(self, text: str) -> bool:
        """Detecta si el texto contiene marcadores de una propuesta completa"""
        markers = [
            "Propuesta",
            "Antecedentes del Proyecto",
            "Objetivo del Proyecto",
            "Par치metros de Dise침o",
            "Proceso de Tratamiento",
        ]

        marker_count = sum(1 for marker in markers if marker in text)
        return marker_count >= 3


# Instancia global
ai_service = AIService()
